import sys
import os
import json
import shutil
from owlready2 import locstr
from rdflib import Graph

# Add the  directory to sys.path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
print(sys.path)

from cold.ontology.importer import import_ontology
from cold.ontology.loader import load_ontology
from cold.ontology.extractor import extract_classes
from cold.ontology.formatter import format_ontology
from cold.models.generator import generate_pydantic_classes
from cold.utils.access import *

CLASSES_OUTPUT_DIR = "cold/models/autogenerated/"
TEMPLATE_PATH = "cold/models/templates/pydantic_template.jinja2"

if os.path.exists(CLASSES_OUTPUT_DIR):
    shutil.rmtree(CLASSES_OUTPUT_DIR)
os.makedirs(CLASSES_OUTPUT_DIR, exist_ok=True)

# Required directories
REQUIRED_DIRECTORIES = [
    "cold/models/autogenerated/",
    "cold/ontology/files/formatted/",
    "cold/ontology/files/originals/",
]

def ensure_directories_exist(directories):
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"Created directory: {directory}")
        else:
            print(f"Directory already exists: {directory}")

def main():
  
    # Ensure required directories exist
    ensure_directories_exist(REQUIRED_DIRECTORIES)
    print(get_path_to_ontology())
    # Import ontology urls from json
    with open(os.path.join(get_path_to_ontology(), "urls.json"), 'r') as f:
        url_dict = json.load(f)

    # Stage 1: Extract classes from all ontologies
    all_classes = []
    class_to_prefix_map = {}
    formatted_paths = []
    lumped_turtle = os.path.join(get_path_to_ontology_files_formatted(), "merged.ttl")

    # Process and collect all ontology paths
    for url_key in url_dict.keys():
        print(f"Processing {url_key} ontology.")

        url = url_dict[url_key]["url"]
        original_file_name = url_dict[url_key]["original_file_name"]
        formatted_file_name = url_dict[url_key]["formatted_file_name"]

        original_file_path = os.path.join(get_path_to_ontology_files_originals(), original_file_name)
        formatted_file_path = os.path.join(get_path_to_ontology_files_formatted(), formatted_file_name)

        import_ontology(url, original_file_path)
        format_ontology(original_file_path, formatted_file_path)

        formatted_paths.append(formatted_file_path)

    # Merge all formatted TTLs into one graph
    print("Merging all formatted ontologies into a single RDF graph...")
    g = Graph()
    for path in formatted_paths:
        g.parse(path, format="turtle")

    # Save merged TTL
    g.serialize(destination=lumped_turtle, format="turtle")
    print(f"Merged TTL written to: {lumped_turtle}")

    # Load as a single ontology
    ontology = load_ontology(lumped_turtle)

    # For each ontology source, extract classes and tag with prefix
    for prefix in url_dict.keys():
        formatted_file_path = os.path.join(get_path_to_ontology_files_formatted(), url_dict[prefix]["formatted_file_name"])
        sub_ontology = load_ontology(formatted_file_path)
        extracted = extract_classes(sub_ontology)
        all_classes.extend([(cls, prefix) for cls in extracted])


    # Stage 2: Generate Pydantic classes
    generate_pydantic_classes(all_classes, TEMPLATE_PATH, CLASSES_OUTPUT_DIR)

if __name__ == "__main__":
    main()
